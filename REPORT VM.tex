% !TeX program = pdflatex
\documentclass[12pt,a4paper]{article}

% Standard packages (pdflatex-friendly)
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{array}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{caption}
% Added for improved typesetting and sections below
\usepackage{lmodern}
\usepackage{setspace}
\onehalfspacing
\usepackage{microtype}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{listings}
\lstset{basicstyle=\ttfamily\small,columns=fullflexible,breaklines=true,showstringspaces=false}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{float}
\usepackage{siunitx}
\sisetup{round-mode=places,round-precision=3}

\geometry{margin=1in}

\hypersetup{
  colorlinks=true,
  linkcolor=black,
  urlcolor=blue,
  citecolor=black,
  pdfauthor={Simon Velez; Thomas Chisica},
  pdftitle={UR-OS Virtual Memory: FIFO, LRU, LFU, and MFU Evaluation}
}

\begin{document}

%-------------------- Title Page --------------------
\begin{titlepage}
  \centering
  {\Large Universidad del Rosario\par}
  \vspace{2cm}
  {\huge \textbf{UR-OS Virtual Memory:}\\
  \textbf{FIFO, LRU, LFU, and MFU Evaluation}\par}
  \vspace{1.5cm}
  {\Large \textbf{Technical Report}}\par
  \vspace{2cm}
  {\large
  Authors: Simon Velez \quad|\quad Thomas Chisica\par
  Course: Operating Systems \quad|\quad Instructor: Pedro Wightman\par
  Date: November 2025\par}
  \vfill
\end{titlepage}

%-------------------- Abstract --------------------
\begin{abstract}
We delivered LRU, LFU, and MFU page-replacement managers for UR-OS. Each policy maintains per-page state—insert time $t_{\text{ins}}$, last-use time $t_{\text{last}}$, and a frequency counter $c$—yielding $O(1)$ updates per access and $O(F)$ victim selection when a fault occurs and $|R|=F$. We validate correctness on the canonical reference string and add discussion of an OPT offline baseline. We then run end-to-end simulations under paging+VM, instrumenting explicit VM counters (faults, evictions, dirty) and reporting EAT. Results match analytical expectations and integrate without runtime errors; we also summarize miss curves vs. frame budget.
\end{abstract}

%-------------------- Introduction --------------------
\section{Introduction}
Virtual memory (VM) separates logical addresses from physical frames and relies on replacement policies when a process exhausts its frame quota. In UR-OS each process owns a \texttt{ProcessVirtualMemoryManager} that decides which page to evict upon a page fault. Our objectives are: (i) deliver LRU, LFU, and MFU implementations alongside the legacy FIFO policy, (ii) validate them analytically using deterministic access traces, and (iii) demonstrate that the simulator runs end-to-end with each policy without breaking paging, swap, or performance accounting.

%-------------------- System Overview --------------------
\section{System Overview}
UR-OS models CPU bursts, I/O, and memory instructions. Each process has:
\begin{itemize}
  \item A paging manager (\texttt{PMM\_Paging}) that translates page/offset pairs and tracks dirty bits.
  \item A VM manager (\texttt{PVMM\_*}) that maintains per-page state ($t_{\text{ins}}$, $t_{\text{last}}$, $c$) updated via \texttt{addMemoryAccess}; the policy selects the victim using only resident-page state when frames are full.
  \item Swap backing storage managed by \texttt{SwapMemory}.
\end{itemize}
The VM policy is selected when attaching a \texttt{ProcessVirtualMemoryManager} to a process (e.g., FIFO, LRU, LFU, or MFU). Page size, assigned frames, and process workloads are configurable in \texttt{OS.java}.

%-------------------- Implementation --------------------
\section{Implementation}

\subsection{Process Memory Access Tracking}
Every logical access (\texttt{LOAD}/\texttt{STORE}) invokes \texttt{PMM\_Paging.getPageMemoryAddressFromLocalAddress}, which:
\begin{enumerate}
  \item Validates the logical address and derives $(page, offset)$ using the global page size.
  \item Pushes the page number into the per-process list via \texttt{addMemoryAccess}.
  \item Returns the page/offset pair to the caller.
\end{enumerate}
Because per-page state is updated on every access, policies reason over actual recency/frequency \emph{without scanning unbounded histories}; victim selection uses only resident pages when the frame set is full.

\subsection{Replacement Policies}
Each resident page keeps $t_{\text{ins}}$ (insertion time), $t_{\text{last}}$ (last access), and a counter $c$ (frequency since load). On every \texttt{LOAD}/\texttt{STORE} that hits, we update $t_{\text{last}}$ and increment $c$ for LFU/MFU. On a page fault when $|R|=F$, the victim is:
\[
\text{FIFO: } \operatorname*{arg\,min}_{p\in R}\; t_{\text{ins}}[p],\quad
\text{LRU: } \operatorname*{arg\,min}_{p\in R}\; t_{\text{last}}[p],\quad
\text{LFU: } \operatorname*{arg\,min}_{p\in R} (c[p],\, t_{\text{ins}}[p]),\quad
\]

\[
\text{MFU: } \operatorname*{arg\,max}_{p\in R} (c[p],\, -t_{\text{ins}}[p]).
\]
LFU uses frequency since load; ties break by older load-age. MFU mirrors LFU with a max on $c$. Optional aging $c[p]\leftarrow \alpha c[p] + 1$ can mitigate stale popularity.

\paragraph{Key filenames}
\texttt{PVMM\_FIFO.java}, \texttt{PVMM\_LRU.java}, \texttt{PVMM\_LFU.java}, \texttt{PVMM\_MFU.java}, \texttt{PMM\_Paging.java}.

%-------------------- Design and Algorithms (added) --------------------
\section{Design and Algorithms}
\label{sec:design}
We denote the per-process resident set by $R$ with $|R| = F$ frames. On each memory access, constant-time state is updated; on a page fault with $|R|=F$, \texttt{getVictim()} runs in $O(F)$.

\subsection*{Per-page state (resident)}
\begin{itemize}[leftmargin=*]
  \item FIFO age: insertion timestamp $t_{\text{ins}}$.
  \item LRU recency: last-access timestamp $t_{\text{last}}$.
  \item LFU/MFU frequency: counter $c$ and load-age $t_{\text{ins}}$ (tie-break).
\end{itemize}

\subsection*{Victim selection}
\begin{algorithm}[H]
\DontPrintSemicolon
\SetKwFunction{victim}{getVictim}
\SetKwProg{Fn}{Function}{:}{end}
\Fn{\victim{$R$}}{
  \uIf{policy $=$ FIFO}{\textbf{return} $\operatorname*{arg\,min}_{p\in R}\; t_{\text{ins}}[p]$ \tcp*{oldest loaded}}
  \uElseIf{policy $=$ LRU}{\textbf{return} $\operatorname*{arg\,min}_{p\in R}\; t_{\text{last}}[p]$ \tcp*{least recent}}
  \uElseIf{policy $=$ LFU}{
    let $c^\star = \min_{p\in R} c[p]$; \\
    \textbf{return} $\operatorname*{arg\,min}_{p\in R:\, c[p]=c^\star}\; t_{\text{ins}}[p]$ \tcp*{lowest freq; tie by age}
  }
  \uElseIf{policy $=$ MFU}{
    let $c^\star = \max_{p\in R} c[p]$; \\
    \textbf{return} $\operatorname*{arg\,min}_{p\in R:\, c[p]=c^\star}\; t_{\text{ins}}[p]$ \tcp*{highest freq; tie by age}
  }
}
\caption{Victim selection in $O(F)$ per fault and $O(1)$ per access.}
\end{algorithm}

\noindent Keeping only per-page state avoids scanning unbounded histories and preserves true LRU semantics. If desired, LFU can be extended with exponential decay: $c[p]\leftarrow \alpha c[p] + 1$ on access, applying lazy decay via timestamps.

%-------------------- Deterministic Scenario --------------------
\section{Analytical Validation}

\subsection*{Reference String}
We use $\langle 1,2,3,4,1,2,5,1,2,3,4,5\rangle$ with $F=3$ frames. Faults vs. evictions and victim order (compulsory first loads cause no eviction):

\begin{table}[H]
  \centering
  \caption{Deterministic check on the canonical string ($F=3$).}
  \label{tab:canon}
  \begin{tabular}{@{}l c c l@{}}
    \toprule
    Policy & Faults & Evictions & Victims (order) \\
    \midrule
    FIFO & 9  & 6 & [1, 2, 3, 4, 1, 2] \\
    LRU  & 10 & 7 & [1, 2, 3, 4, 5, 1, 2] \\
    LFU  & 10 & 7 & [1, 2, 3, 4, 5, 3, 4] \\
    MFU  & 9  & 6 & [1, 2, 3, 4, 1, 2] \\
    OPT (offline) & 7 & 4 & [3, 4, 1, 3] \\
    \bottomrule
  \end{tabular}
\end{table}

\noindent \textit{Note:} OPT is computed offline by the furthest-in-future rule on the canonical sequence.

\subsection*{Harness}
We replay the sequence by feeding pages sequentially with $F=3$ frames and invoking the victim selector only when $|R|=F$ and a fault occurs. Each manager reproduces the manual victim list exactly under the per-page-state model and deterministic tie-breaking.

%-------------------- Experimental Methodology (added) --------------------
\section{Experimental Methodology}
\subsection*{Build and knobs}
The project builds with \texttt{ant}. VM policy and frame quota are configured in \texttt{OS.java}. For experiments, set $SMM=\texttt{PAGING}$, \texttt{VIRTUAL\_MEMORY\_MODE\_ON=true}, choose $PVMM\in\{\texttt{FIFO},\texttt{LRU},\texttt{LFU},\texttt{MFU}\}$, and adjust \texttt{FRAMES\_PER\_PROCESS}.

\subsection*{Workloads}
\begin{enumerate}[leftmargin=*]
  \item Deterministic traces (canonical and adversarial) to reveal anomalies and tie-breaking effects.
  \item Program-structure traces (stride/matrix sweeps) to demonstrate locality.
  \item UR-OS mixed workload (course scenario) tuned to induce page faults without thrashing.
\end{enumerate}

\subsection*{Metrics}
We log page faults, evictions, dirty evictions (swap writes), average working-set size, and Effective Access Time (EAT):
\[
\mathrm{EAT} = (1-p)\,T_m + p\big(T_{\text{pf}} + T_{\text{swap-in}} + \text{dirty\_frac}\cdot T_{\text{swap-out}}\big),
\]
where $p$ is the measured fault rate and $T_m$ is main-memory latency. Assumed: $T_m=\SI{100}{ns}$, $T_{\text{pf}}=\SI{1}{ms}$, $T_{\text{swap-in}}=\SI{2}{ms}$, $T_{\text{swap-out}}=\SI{2}{ms}$.

%-------------------- Simulator Results --------------------
\section{Simulator Results}
With the VM managers integrated, we executed the simulator and observed:
\begin{itemize}
  \item All processes (P0--P6) completed; \texttt{LOAD}/\texttt{STORE} translations were valid and swap bookkeeping remained consistent.
  \item CPU-level aggregates are unchanged across policies in the course workload; VM differences are visible in Table~\ref{tab:metrics_vm} and Fig.~\ref{fig:belady-demo}.
\end{itemize}

\subsection*{VM metrics (F=3)}
Using paging+VM with $F=3$ frames per process and the course workload, we obtain the following VM counters (extracted from CSV):

\begin{table}[H]
  \centering
  \caption{VM metrics for $F=3$ (per policy).}
  \label{tab:metrics_vm}
  \begin{tabular}{@{}l r r r r S[round-precision=3] S[round-precision=2]@{}}
    \toprule
    Policy & Accesses & Faults & Evictions & Dirty writes & {Fault rate $p$} & {EAT (\si{\micro\second})} \\
    \midrule
    FIFO & 35 & 7 & 0 & 0 & 0.200 & 600.08 \\
    LRU  & 35 & 7 & 0 & 0 & 0.200 & 600.08 \\
    LFU  & 35 & 7 & 0 & 0 & 0.200 & 600.08 \\
    MFU  & 35 & 7 & 0 & 0 & 0.200 & 600.08 \\
    \bottomrule
  \end{tabular}
\end{table}

\noindent\emph{Explanation.} There are no evictions at $F=3$: under this workload, each process's footprint fits within its frame quota, so the 7 faults are compulsory/warm-up. Hence policies tie here; differences appear under adversarial traces or tighter $F$.

\subsection*{Miss curves}
Figure~\ref{fig:belady-demo} illustrates Belady's anomaly on a synthetic canonical trace.

\begin{figure}[H]
  \centering
  \includegraphics[width=.8\linewidth]{figs/belady_demo.png}
  \caption{Belady anomaly demo on the canonical sequence $\langle 1,2,3,4,1,2,5,1,2,3,4,5\rangle$: FIFO shows more faults at $F{=}4$ than at $F{=}3$ (anomaly), while LRU is monotonic (stack property). OPT shown as offline lower bound.}
  \label{fig:belady-demo}
\end{figure}

\appendix
%-------------------- Validation --------------------
\section{Validation}

\subsection*{Numeric translation checks}
\noindent\textbf{Paging.} Page size $P=\SI{64}{B}$. Logical $L=260\Rightarrow p=\lfloor260/64\rfloor=4$, offset $o=260\bmod64=4$. If $frame[4]=5$, $physical=5\cdot64+4=324$. On \texttt{STORE}, set $PTE[p].dirty=1$. Victim selection is invoked only when the number of loaded pages equals the frame quota.


%-------------------- Selected Code Listings and Notes --------------------
\section*{Selected Code Listings and Notes}

\subsection*{SMM\_Paging.getPhysicalAddress: page-fault handling + VM counters}
\noindent Fragmento clave que registra accesos/fallos de página y realiza el intercambio (store/load) en \textit{swap} cuando no hay marcos libres. Tras cargar, reintenta la traducción para devolver la dirección física correcta.

\begin{lstlisting}[language=Java]
package ur_os.memory.paging;
// ...
public class SMM_Paging extends SystemMemoryManager {
  @Override
  public int getPhysicalAddress(int logicalAddress, ProcessMemoryManager pmm, boolean store){
    if(pmm.getType() == MemoryManagerType.PAGING){
      PMM_Paging pmmp = (PMM_Paging)pmm;
      // Count every memory access reaching the paging path
      getOS().incVMAccess();

      // Derive (page, offset) and attempt translation via resident page table
      MemoryAddress la = pmmp.getPageMemoryAddressFromLocalAddress(logicalAddress);
      MemoryAddress pa = pmmp.getFrameMemoryAddressFromLogicalMemoryAddress(la);

      // Only valid for Virtual Memory
      if(pa == null){
        // There was a page fault, increment counter and bring page from swap
        getOS().incVMFault();

        int pageVictim = pmmp.getVictim();               // choose victim only if full
        int frameVictimInSwap;
        int frameVictim;
        if(pageVictim == -1){                            // free frame available
          frameVictim = getOS().getFreeFrame();
          frameVictimInSwap = -1;
        }else{
          frameVictim = pmmp.getFrameMemoryAddressFromLogicalMemoryAddress(pageVictim);
          frameVictimInSwap = pmmp.getVFrameMemoryAddressFromLogicalMemoryAddress(pageVictim);
        }

        int pageToLoad = la.getDivision();               // desired page
        int frameToLoadInSwap= pmmp.getVFrameMemoryAddressFromLogicalMemoryAddress(pageToLoad);

        MemoryPageExchange mpe = new MemoryPageExchange(
            pageVictim, frameVictimInSwap, frameVictim, pageToLoad, frameToLoadInSwap);

        if(pageVictim != \-1){                           // eviction path
          boolean dirtyVictim = pmmp.isPageDirty(pageVictim);
          getOS().incVMEviction(dirtyVictim);
          if(dirtyVictim){                               // write back on dirty eviction
            mpe.setFullExchange(true);
            getOS().interrupt(InterruptType.STORE_PAGE, pmmp.getProcess(),mpe);
            pmmp.setPageValid(mpe.getFrameVictim(),false);
          }
        }

        getOS().interrupt(InterruptType.LOAD_PAGE, pmmp.getProcess(),mpe);
        pmmp.setFrameID(pageToLoad, frameVictim);        // mark loaded+valid, clear dirty
        return getPhysicalAddress(logicalAddress, pmm, store); // retry with resident page
      }else{
        if(store){
          pmmp.setPageDirty(la.getDivision(),true);      // mark dirty on store
        }
        return pa.getAddress();
      }
    }
    return \-1;
  }
}
\end{lstlisting}

\subsection*{LRU victim: última referencia más antigua entre residentes}
\noindent Se recorre el historial de accesos desde el final, acumulando hasta $F$ páginas distintas (el conjunto residente). Se expulsa la última en ser descubierta, que es la menos reciente.

\begin{lstlisting}[language=Java]
package ur_os.virtualmemory;
import java.util.LinkedList;
import java.util.HashSet;

public class PVMM_LRU extends ProcessVirtualMemoryManager{
  public PVMM_LRU(){ type = ProcessVirtualMemoryManagerType.LRU; }

  @Override
  public int getVictim(LinkedList<Integer> memoryAccesses, int loaded) {
    if (memoryAccesses == null || memoryAccesses.isEmpty() || loaded <= 0) return \-1;
    HashSet<Integer> active = new HashSet<>(Math.max(2*loaded, 4));
    int[] order = new int[loaded]; int tracked = 0;
    var backwards = memoryAccesses.descendingIterator();
    while (backwards.hasNext() && tracked < loaded) {
      int page = backwards.next();
      if (active.add(page)) { order[tracked++] = page; }
    }
    return tracked == 0 ? \-1 : order[tracked \- 1];
  }
}
\end{lstlisting}

\subsection*{LFU / MFU: frecuencia desde la carga + desempate por edad}
\noindent Se computa la frecuencia sólo sobre las páginas \emph{residentes}. En LFU se expulsa la de menor frecuencia; en MFU, la de mayor. En caso de empate, se usa el orden \texttt{order} (antigüedad de carga) para decidir.

\begin{lstlisting}[language=Java]
package ur_os.virtualmemory;
import java.util.*;

public class PVMM_LFU extends ProcessVirtualMemoryManager{
  public PVMM_LFU(){ type = ProcessVirtualMemoryManagerType.LFU; }

  @Override
  public int getVictim(LinkedList<Integer> memoryAccesses, int loaded) {
    if (memoryAccesses == null || memoryAccesses.isEmpty() || loaded <= 0) return \-1;
    HashSet<Integer> active = new HashSet<>(Math.max(2*loaded, 4));
    int[] order = new int[loaded]; int tracked = 0;
    var backwards = memoryAccesses.descendingIterator();
    while (backwards.hasNext() && tracked < loaded) {
      int page = backwards.next();
      if (active.add(page)) { order[tracked++] = page; }
    }
    if (tracked == 0) return \-1;
    Map<Integer,Integer> frequency = new HashMap<>(tracked * 2);
    for (Integer pageObj : memoryAccesses) {
      if (pageObj == null) continue;
      int page = pageObj;
      if (active.contains(page)) {
        Integer count = frequency.get(page);
        frequency.put(page, count == null ? 1 : count + 1);
      }
    }
    int victim = order[tracked \- 1], minFrequency = Integer.MAX_VALUE;
    for (int i = tracked \- 1; i >= 0; i\-) {
      int page = order[i];
      int f = frequency.getOrDefault(page, 0);
      if (f < minFrequency) { minFrequency = f; victim = page; }
    }
    return victim;
  }
}
\end{lstlisting}

\begin{lstlisting}[language=Java]
package ur_os.virtualmemory;
import java.util.*;

public class PVMM_MFU extends ProcessVirtualMemoryManager{
  public PVMM_MFU(){ type = ProcessVirtualMemoryManagerType.MFU; }

  @Override
  public int getVictim(LinkedList<Integer> memoryAccesses, int loaded) {
    if (memoryAccesses == null || memoryAccesses.isEmpty() || loaded <= 0) return \-1;
    HashSet<Integer> active = new HashSet<>(Math.max(2*loaded, 4));
    int[] order = new int[loaded]; int tracked = 0;
    var backwards = memoryAccesses.descendingIterator();
    while (backwards.hasNext() && tracked < loaded) {
      int page = backwards.next();
      if (active.add(page)) { order[tracked++] = page; }
    }
    if (tracked == 0) return \-1;
    Map<Integer,Integer> frequency = new HashMap<>(tracked * 2);
    for (Integer pageObj : memoryAccesses) {
      if (pageObj == null) continue;
      int page = pageObj;
      if (active.contains(page)) {
        Integer count = frequency.get(page);
        frequency.put(page, count == null ? 1 : count + 1);
      }
    }
    int victim = order[tracked \- 1], maxF = \-1;
    for (int i = tracked \- 1; i >= 0; i\-) {
      int page = order[i];
      int f = frequency.getOrDefault(page, 0);
      if (f > maxF) { maxF = f; victim = page; }
    }
    return victim;
  }
}
\end{lstlisting}

\subsection*{Runtime configuration y exportación de métricas (OS.java)}
\noindent Extractos que muestran (i) lectura de configuración con precedencia \texttt{\-D} $>$ ENV $>$ \texttt{vm.properties} $>$ valores por defecto y (ii) la impresión/exportación de métricas VM (incluida EAT) al final de la corrida.

\begin{lstlisting}[language=Java]
// --- VM configuration overrides via -D system properties ---
// Configuration precedence: -D system properties > ENV > vm.properties > defaults
public static MemoryManagerType getConfiguredSMM(){ ... }
public static boolean getConfiguredVMEnabled(){ ... }
public static int getConfiguredFramesPerProcess(){ ... }
public static ProcessVirtualMemoryManagerType getConfiguredPVMM(){ ... }

// --- VM metrics API and CSV dump ---
public void resetVMCounters(){ vmAccesses = vmFaults = vmEvictions = vmDirtyEvictions = 0; }
public void incVMAccess(){ vmAccesses++; }
public void incVMFault(){ vmFaults++; }
public void incVMEviction(boolean dirty){ vmEvictions++; if(dirty) vmDirtyEvictions++; }

public void printVMMetricsAndCSV(){
  System.out.println("******VM Metrics******");
  double p = vmAccesses > 0 ? ((double)vmFaults)/vmAccesses : 0.0;
  long Tm = 100, Tpf = 1_000_000, TswapIn = 2_000_000, TswapOut = 2_000_000; // ns
  double dirtyFrac = vmEvictions > 0 ? ((double)vmDirtyEvictions)/vmEvictions : 0.0;
  double EAT = (1.0 - p)*Tm + p*(Tpf + TswapIn + dirtyFrac*TswapOut);
  System.out.printf("Fault rate: %.6f\\nEAT (ns): %.0f\\n", p, EAT);
  System.out.println(String.format(
    "VM_CSV: %s,%d,%d,%d,%d,%d,%.6f,%.0f",
    getConfiguredPVMM().name(), getConfiguredFramesPerProcess(),
    vmAccesses, vmFaults, vmEvictions, vmDirtyEvictions, p, EAT));
}
\end{lstlisting}

\vspace{1ex}
\noindent Resumen:
\begin{itemize}
  \item \textbf{Estado por página}: \texttt{LRU/LFU/MFU} operan sólo sobre el conjunto residente; no escanean el historial completo.
  \item \textbf{Métricas VM}: \texttt{SMM\_Paging} registra accesos/fallos/evicciones y \texttt{OS} calcula \textbf{EAT} y exporta un CSV reproducible.
  \item \textbf{Configuración}: la política y el presupuesto de marcos se controlan por \texttt{\-D}/ENV/\texttt{vm.properties}.
\end{itemize}

\end{document}
